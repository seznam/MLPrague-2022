{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93261085-f592-4b63-8b75-52839c4c7e13",
   "metadata": {
    "id": "93261085-f592-4b63-8b75-52839c4c7e13"
   },
   "source": [
    "# User representation\n",
    " - As was already mentioned earlier it is impossible to supply every recommender system with all raw data comming from other systems due to computational limitations and certain amount of compression is therefore required\n",
    " - Also supplying recommender system with additional data will allow us to personalize model and help us deal with user [cold-start problem](https://en.wikipedia.org/wiki/Cold_start_(recommender_systems))\n",
    " - We will try to create user representation and generally describe methods for obtaining user dense representation also known as embedding from user page visits\n",
    " - Supervised aproach:\n",
    "   - Assume that you own large portfolio of various websites and you could categorize websites into the following categories: sport, news and tabloid \n",
    "   - Assume user $U$ visited following webpages [PV1](https://www.sport.cz/clanek/fotbal-ceska-1-liga-fotbal-online-provod-tahne-slavii-na-prvni-misto-banik-doma-zklamal-jablonec-na-snehu-vyrovnal-3273466), [PV2](https://www.sport.cz/clanek/hokej-jagr-mladez-na-kladne-je-i-ma-ostuda-se-vzkrisenim-slavne-znacky-mu-pomuze-plekanec-coby-sef-3274015), [PV3](https://www.super.cz/862981-obrazem-21-modelu-z-ceskeho-plesu-z-obrich-dekoltu-a-rozparku-se-vam-zatoci-hlava.html)\n",
    "   - Then one could represent $U$ as sequence of the following categories: sport, sport, tabloid\n",
    "   - This sequence can be further preprocessed into histogram or viewed as text document and be processed by some NLP technique such as [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "   - Having such information associated with user or a page will be important for user and item cold-start mitigation\n",
    "   - The main question is how can one receive such classification? One needs to build online classification service that will detect newly created web pages and classify them appropriately\n",
    " - Unsupervised aproach:\n",
    "    - In an unsupervised aproach one does not need any additional information regarding user content labels - only sequence of visited webpage views for every user\n",
    "    - Assume that user $U$ has visided pages PV1, PV2, PV3 then we can treat user as a document and visited web pages as words and create word embeddings by using NLP techniques\n",
    "    - One can then represent $U$ as a sequence of vectors which can be further aggregated into single vector\n",
    "    - There are many NLP libraries available:\n",
    "      - [fasttext](https://fasttext.cc/)\n",
    "      - [starspace](https://github.com/facebookresearch/StarSpace)\n",
    "      - [doc2vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "      - [word2vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "      - Also one can choose to use more complex methods such as [bert](https://github.com/google-research/electra)\n",
    "      \n",
    "      \n",
    "  - Article's categories and subcategories are already available in MIND dataset therefore we will focus on creating unsupervised user representation using `fasttext` and visualizing it via [umap](https://umap-learn.readthedocs.io/en/latest/parameters.html) dimensionality reduction algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb99f1f-a1ac-4bcb-ba35-b88f80d5afe3",
   "metadata": {
    "id": "cbb99f1f-a1ac-4bcb-ba35-b88f80d5afe3"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/seznam/MLPrague-2022.git umap-learn==0.5.2 fasttext==0.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10abde1",
   "metadata": {
    "id": "P2l1cTjr55Oj"
   },
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from mlprague22.util import mount_gdrive\n",
    "BASE_DIR, IN_COLAB = mount_gdrive(\"mlprague2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61532fd-84ae-4bc0-a944-dcac672fa074",
   "metadata": {
    "id": "f61532fd-84ae-4bc0-a944-dcac672fa074"
   },
   "outputs": [],
   "source": [
    "# import necessary functionality\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fd44e-adba-493d-863e-ab4caae3a664",
   "metadata": {
    "id": "712fd44e-adba-493d-863e-ab4caae3a664"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"data/mind_cold_start_datasets_basic/\")\n",
    "\n",
    "COLD_START_BEHAVIORS_TRAIN = os.path.join(OUTPUT_DIR, \"behaviors_train.tsv\")\n",
    "COLD_START_BEHAVIORS_TEST = os.path.join(OUTPUT_DIR, \"behaviors_test.tsv\")\n",
    "NEWS_CATALOGUE_TRAIN = os.path.join(OUTPUT_DIR, \"news_catalogue_train.tsv\")\n",
    "NEWS_CATALOGUE_TEST = os.path.join(OUTPUT_DIR, \"news_catalogue_test.tsv\")\n",
    "AUXILIARY_DATA_CATALOGUE_TRAIN = os.path.join(OUTPUT_DIR, \"auxiliary_data_catalogue_train.tsv\")\n",
    "\n",
    "EMBEDDINGS_OUTPUT_DIR = os.path.join(OUTPUT_DIR, \"embeddings\")\n",
    "FT_HISTORY_EMBEDDINGS_TRAIN = \"ft_histories_train.vec\"\n",
    "FT_HISTORY_EMBEDDINGS_TEST = \"ft_histories_test.vec\"\n",
    "EMBEDDINGS_OUTPUT_TRAIN = os.path.join(EMBEDDINGS_OUTPUT_DIR, FT_HISTORY_EMBEDDINGS_TRAIN)\n",
    "EMBEDDINGS_OUTPUT_TEST = os.path.join(EMBEDDINGS_OUTPUT_DIR, FT_HISTORY_EMBEDDINGS_TEST)\n",
    "\n",
    "FASTTEXT_MODEL_FILE = os.path.join(BASE_DIR, \"models\", \"fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba116f8f-511a-466e-ab60-177c885125ba",
   "metadata": {
    "id": "ba116f8f-511a-466e-ab60-177c885125ba"
   },
   "outputs": [],
   "source": [
    "def visualize_embeddings_umap(embeddings_train, embeddings_test, labels_train, labels_test, info, ignore_labels):\n",
    "  \"\"\"Functionality for embedding visualization.\"\"\"\n",
    "  label2id = {l: i for i, l in enumerate(sorted(set([_l for _l in labels_train if str(_l) != 'nan'])))}\n",
    "  pal = sns.color_palette(n_colors=len(label2id))\n",
    "\n",
    "  reducer = umap.UMAP(metric=\"cosine\", )\n",
    "  umap_embeddings_train = reducer.fit_transform(embeddings_train)\n",
    "  umap_embeddings_test = reducer.transform(embeddings_test)\n",
    "\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n",
    "  fig.suptitle(f\"UMAP projection of embeddings - {info}\", fontsize=20)\n",
    "\n",
    "  def _plot(ax, umap_embeddings, labels):\n",
    "      for label in list(label2id.keys()):\n",
    "          if label in ignore_labels:\n",
    "              continue\n",
    "          mask = labels == label\n",
    "          ax.scatter(\n",
    "              umap_embeddings[mask, 0],\n",
    "              umap_embeddings[mask, 1],\n",
    "              color=pal[label2id[label]],\n",
    "              label=label\n",
    "          )\n",
    "      ax.legend()\n",
    "      ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "  _plot(ax1, umap_embeddings_train, labels_train)\n",
    "  _plot(ax2, umap_embeddings_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a52cb1-2031-4092-8d66-2acf0a274949",
   "metadata": {
    "id": "94a52cb1-2031-4092-8d66-2acf0a274949"
   },
   "outputs": [],
   "source": [
    "behaviors_train = pd.read_csv(COLD_START_BEHAVIORS_TRAIN, sep=\"\\t\")\n",
    "behaviors_test = pd.read_csv(COLD_START_BEHAVIORS_TEST, sep=\"\\t\")\n",
    "news_train = pd.read_csv(NEWS_CATALOGUE_TRAIN, sep=\"\\t\")\n",
    "\n",
    "# use only unique users for training\n",
    "dataset_train_unique_users = (\n",
    "    behaviors_train.sort_values(\"time\")\n",
    "    .drop_duplicates(\"userid\", keep=\"first\")\n",
    "    .reset_index()\n",
    ")\n",
    "dataset_test_unique_users = (\n",
    "    behaviors_test.sort_values(\"time\")\n",
    "    .drop_duplicates(\"userid\", keep=\"first\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add197de-bb6b-4cf9-a7b1-bcd768c9a4af",
   "metadata": {
    "id": "add197de-bb6b-4cf9-a7b1-bcd768c9a4af"
   },
   "outputs": [],
   "source": [
    "# fasttext requires training data to be in a specific format\n",
    "# every line will contain user page views delimited by space\n",
    "with open('/tmp/ft_histories_train.txt', 'w') as f:\n",
    "    for h in dataset_train_unique_users[\"history_all\"]:\n",
    "        f.write(f\"{h}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66d715-c772-4c68-8461-f0dda78faa73",
   "metadata": {
    "id": "4c66d715-c772-4c68-8461-f0dda78faa73"
   },
   "outputs": [],
   "source": [
    "# training of fasttext model\n",
    "# fasttext would normaly try to derive sub-word embeddings which might make sense for text documents but it is useless for webpages => maxn=0\n",
    "ft_model_histories = fasttext.train_unsupervised(\"/tmp/ft_histories_train.txt\", maxn=0, dim=100, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed801d-baac-43a1-bd8b-2c1ca8c4c05a",
   "metadata": {
    "id": "35ed801d-baac-43a1-bd8b-2c1ca8c4c05a"
   },
   "outputs": [],
   "source": [
    "# certain articles occure very little - it does make sense to visualize them as they would harm our visualization => filter them out\n",
    "aux_catalogue_train = pd.read_csv(AUXILIARY_DATA_CATALOGUE_TRAIN, sep=\"\\t\")\n",
    "\n",
    "histories_popularity_train = (\n",
    "    dataset_train_unique_users.assign(\n",
    "        history_all_arr=lambda x: [r.split() for r in x[\"history_all\"]]\n",
    "    )[[\"history_all_arr\"]]\n",
    "    .explode(\"history_all_arr\")\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "histories_popularity_test = (\n",
    "    dataset_test_unique_users.assign(\n",
    "        history_all_arr=lambda x: [r.split() for r in x[\"history_all\"]]\n",
    "    )[[\"history_all_arr\"]]\n",
    "    .explode(\"history_all_arr\")\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "histories_popularity_train.columns = [\"newsid\", \"user_history_occurences\"]\n",
    "histories_popularity_test.columns = [\"newsid\", \"user_history_occurences\"]\n",
    "\n",
    "aux_catalogue_train_no_longtail = aux_catalogue_train.merge(histories_popularity_train, on=\"newsid\").query(\"user_history_occurences >= 5\")\n",
    "aux_catalogue_test_no_longtail =  aux_catalogue_train.merge(histories_popularity_test, on=\"newsid\").query(\"user_history_occurences >= 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b93d16-2c22-4103-8039-45fee5fbb0e5",
   "metadata": {
    "id": "64b93d16-2c22-4103-8039-45fee5fbb0e5"
   },
   "outputs": [],
   "source": [
    "# gather embeddings for arcticles \n",
    "ft_histories_item_vectors_train_viz = np.array(\n",
    "    [\n",
    "        np.array(ft_model_histories.get_word_vector(x))\n",
    "        for x in tqdm(aux_catalogue_train_no_longtail[\"newsid\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "ft_histories_item_vectors_test_viz = np.array(\n",
    "    [\n",
    "        np.array(ft_model_histories.get_word_vector(x))\n",
    "        for x in tqdm(aux_catalogue_test_no_longtail[\"newsid\"])\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b518e1-9c83-4c26-b937-ed3ad683a0dd",
   "metadata": {
    "id": "50b518e1-9c83-4c26-b937-ed3ad683a0dd"
   },
   "outputs": [],
   "source": [
    "# visualize items in train/test dataset\n",
    "# label articles in the vector space by their category \n",
    "visualize_embeddings_umap(\n",
    "    ft_histories_item_vectors_train_viz,\n",
    "    ft_histories_item_vectors_test_viz,\n",
    "    aux_catalogue_train_no_longtail[\"category\"],\n",
    "    aux_catalogue_test_no_longtail[\"category\"],\n",
    "    \"items - fasttext histories - category label\",\n",
    "    [\"news\"] # news category is too popular and it would harm our visualization -> ignore it\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GyQgr2mCRwIS",
   "metadata": {
    "id": "GyQgr2mCRwIS"
   },
   "outputs": [],
   "source": [
    "# create user embedding by aggregating word level embeddings\n",
    "# https://github.com/facebookresearch/fastText/blob/26bcbfc6b288396bd189691768b8c29086c0dab7/src/fasttext.cc#L474\n",
    "ft_histories_user_vectors_train = np.array(\n",
    "    [\n",
    "        np.array(ft_model_histories.get_sentence_vector(x))\n",
    "        for x in behaviors_train[\"history_all\"]\n",
    "    ]\n",
    ")\n",
    "ft_histories_user_vectors_test = np.array(\n",
    "    [\n",
    "        np.array(ft_model_histories.get_sentence_vector(x))\n",
    "        for x in behaviors_test[\"history_all\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cd2e8-7f85-4768-b902-f85b23faf840",
   "metadata": {
    "id": "889cd2e8-7f85-4768-b902-f85b23faf840"
   },
   "outputs": [],
   "source": [
    "# save embeddings so we can reuse them in ranking model\n",
    "os.makedirs(EMBEDDINGS_OUTPUT_DIR, exist_ok=True)\n",
    "np.savetxt(EMBEDDINGS_OUTPUT_TRAIN, ft_histories_user_vectors_train, delimiter=\",\")\n",
    "np.savetxt(EMBEDDINGS_OUTPUT_TEST, ft_histories_user_vectors_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RgpHRFnkYm6J",
   "metadata": {
    "id": "RgpHRFnkYm6J"
   },
   "source": [
    "# Exercise\n",
    " - Try to create user embeddings by using page titles instead of arcticles identifiers\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kopie se≈°itu 003-user-representation-embedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
